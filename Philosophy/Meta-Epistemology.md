- An [[Epistemology]] is a set of rules of inference that let you take a set of observations as input and develop a set of beliefs as output. Rules of inference can take as input an observation, a belief, nothing (epsilon), or a proposition combining those things. The statements in the output set are justified by the epistemic system.
	- This is the ideal. In practice, people try to implement their endorsed epistemology, but with limited computing power and noisy implementation.
- Because (ideal) epistemology is like a formal system, there's a thing here like the difference between truth vs provability in formal systems. An [[Epistemology]] can justify claims, like how a formal system can prove theorems. But I'm not sure what exactly it means for a statement to be "true", independent of any epistemology.
- Different people in different circumstances but confronted with the same bank of evidence might have different goals. This is true even if you're a moral realist, because they might have different instrumental goals. So different epistemologies are most useful for different people. When you define [[Ethics]] as "all normativity", it's a tautology to say that your epistemology should be optimized to serve your ethics. Thus, different people should (normatively) use different epistemologies.
- This makes truth a complicated concept. Strictly speaking, the definition of truth I endorse is "the belief that is maximally useful for my goals". This means that truth is determined by an agent's goal - for me, that's [[Ethics]].
	- For practical reasons, I think this will usually be the same as "the belief that makes the most accurate predictions".
	- Frankly, there is still a lot of intuitive pull for me to roll back all this relativist stuff and just define truth in terms of correspondence to [[Reality]]. If I ever figure out how to talk about Reality coherently, that may happen.
- This allows me to explain the complete foundation of my meta-epistemology: [[Ethics]] determines truth, and [[Epistemology]] is a formal system that tries to model truth as accurately as possible. It all comes back to the goal, baby.

- Open question: how to assess the degree of success, in order to choose an epistemology? Can't be assessed based on the epistemology itself, otherwise the epistemology "this epistemology is maximally successful at ~GOAL~" always wins.
	- How to prevent infinite regress?
- The problem of trapped priors asks "how do we know our epistemology isn't sufficiently busted to keep us from realizing it's busted?" I think the answer is just that we can't, but that doesn't matter. To posit a way we could know that requires that all possible epistemologies eventually converge to truth, which is trivially false. A rock can't reason its way to truth from the null epistemology, and there's nothing wrong with that. It's unfortunate, but doesn't yield a contradiction or anything.